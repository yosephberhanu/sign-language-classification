{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd20f179",
   "metadata": {},
   "source": [
    "## Sign Langauge Digit Recognition \n",
    "\n",
    "Sign lanaguge digit recognition using CNN\n",
    "Date credit https://github.com/ardamavi/Sign-Language-Digits-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40ae7128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: scikit-learn in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: tensorflow in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: matplotlib in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (3.6.2)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.9.0-cp38-cp38-macosx_10_15_x86_64.whl (35.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: packaging in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (0.28.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorflow) (22.11.23)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from mediapipe) (21.4.0)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.6.0.66-cp36-abi3-macosx_10_15_x86_64.whl (56.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.1 MB 166 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/yoseph/opt/anaconda3/envs/udacity/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Installing collected packages: opencv-contrib-python, mediapipe\n",
      "Successfully installed mediapipe-0.9.0 opencv-contrib-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python scikit-learn tensorflow matplotlib mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73165584",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e4c71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 07:11:47.378759: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb40697",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd4203",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc302ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root, categories, image_size = 100):\n",
    "    training_data=[]\n",
    "    for category in categories:\n",
    "        path = os.path.join(root, str(category))\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                img_array=cv2.resize(img_array,(image_size, image_size))\n",
    "                training_data.append([img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for c, label in training_data:\n",
    "        X.append(c)\n",
    "        y.append(label)\n",
    "    return np.array(X).reshape(-1, image_size, image_size, 3), np.array(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3932171",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(\"data\", range(10), image_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5d7a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062, 100, 100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37930e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2cc3f",
   "metadata": {},
   "source": [
    "## 3. Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5084b134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X shape (1649, 100, 100, 3)\n",
      "Validation X shape (413, 100, 100, 3)\n",
      "Training y shape (1649, 10)\n",
      "Validation y shape (413, 10)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode y\n",
    "y = to_categorical(y)\n",
    "train_X, validation_X, train_y, validation_y = train_test_split(X, y, test_size = 0.2, random_state=2)\n",
    "print(\"Training X shape\",train_X.shape)\n",
    "print(\"Validation X shape\",validation_X.shape)\n",
    "print(\"Training y shape\",train_y.shape)\n",
    "print(\"Validation y shape\",validation_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fd05e",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "769235ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 20:29:04.726568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "epochs = 23\n",
    "batch_size = 16\n",
    "\n",
    "model = Sequential()\n",
    "#\n",
    "model.add(Conv2D(filters = 32, kernel_size = (6,6), padding = 'Same', \n",
    "                 activation ='relu', input_shape = (100,100,3)))\n",
    "model.add(MaxPool2D(pool_size=(4,4)))\n",
    "model.add(Dropout(0.2))\n",
    "#\n",
    "model.add(Conv2D(filters = 64, kernel_size = (4,4),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=(3,3)))\n",
    "model.add(Dropout(0.2))\n",
    "#\n",
    "model.add(Conv2D(filters =128 , kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "# fully connected\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ec8dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "104/104 [==============================] - 10s 87ms/step - loss: 4.4011 - accuracy: 0.1468 - val_loss: 2.1605 - val_accuracy: 0.1792\n",
      "Epoch 2/23\n",
      "104/104 [==============================] - 9s 90ms/step - loss: 1.4874 - accuracy: 0.4439 - val_loss: 0.9438 - val_accuracy: 0.6586\n",
      "Epoch 3/23\n",
      "104/104 [==============================] - 10s 95ms/step - loss: 0.8990 - accuracy: 0.6701 - val_loss: 0.6703 - val_accuracy: 0.8111\n",
      "Epoch 4/23\n",
      "104/104 [==============================] - 10s 99ms/step - loss: 0.7001 - accuracy: 0.7641 - val_loss: 0.4820 - val_accuracy: 0.8523\n",
      "Epoch 5/23\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.5672 - accuracy: 0.7993 - val_loss: 0.3934 - val_accuracy: 0.8983\n",
      "Epoch 6/23\n",
      "104/104 [==============================] - 11s 102ms/step - loss: 0.4877 - accuracy: 0.8363 - val_loss: 0.3242 - val_accuracy: 0.8983\n",
      "Epoch 7/23\n",
      "104/104 [==============================] - 11s 102ms/step - loss: 0.4077 - accuracy: 0.8569 - val_loss: 0.3169 - val_accuracy: 0.9225\n",
      "Epoch 8/23\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.3715 - accuracy: 0.8775 - val_loss: 0.2306 - val_accuracy: 0.9298\n",
      "Epoch 9/23\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.3958 - accuracy: 0.8684 - val_loss: 0.1749 - val_accuracy: 0.9540\n",
      "Epoch 10/23\n",
      "104/104 [==============================] - 9s 88ms/step - loss: 0.3066 - accuracy: 0.8945 - val_loss: 0.2636 - val_accuracy: 0.9128\n",
      "Epoch 11/23\n",
      "104/104 [==============================] - 10s 99ms/step - loss: 0.3251 - accuracy: 0.8878 - val_loss: 0.1903 - val_accuracy: 0.9395\n",
      "Epoch 12/23\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.2460 - accuracy: 0.9115 - val_loss: 0.1909 - val_accuracy: 0.9492\n",
      "Epoch 13/23\n",
      "104/104 [==============================] - 10s 97ms/step - loss: 0.2474 - accuracy: 0.9121 - val_loss: 0.1651 - val_accuracy: 0.9540\n",
      "Epoch 14/23\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 0.2621 - accuracy: 0.9157 - val_loss: 0.1438 - val_accuracy: 0.9661\n",
      "Epoch 15/23\n",
      "104/104 [==============================] - 11s 105ms/step - loss: 0.2223 - accuracy: 0.9218 - val_loss: 0.1677 - val_accuracy: 0.9443\n",
      "Epoch 16/23\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.2117 - accuracy: 0.9333 - val_loss: 0.1332 - val_accuracy: 0.9685\n",
      "Epoch 17/23\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.1825 - accuracy: 0.9394 - val_loss: 0.1355 - val_accuracy: 0.9637\n",
      "Epoch 18/23\n",
      "104/104 [==============================] - 12s 117ms/step - loss: 0.2558 - accuracy: 0.9272 - val_loss: 0.1360 - val_accuracy: 0.9564\n",
      "Epoch 19/23\n",
      "104/104 [==============================] - 11s 104ms/step - loss: 0.2114 - accuracy: 0.9309 - val_loss: 0.1453 - val_accuracy: 0.9564\n",
      "Epoch 20/23\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.1719 - accuracy: 0.9424 - val_loss: 0.1495 - val_accuracy: 0.9516\n",
      "Epoch 21/23\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.2046 - accuracy: 0.9315 - val_loss: 0.1403 - val_accuracy: 0.9540\n",
      "Epoch 22/23\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 0.1769 - accuracy: 0.9418 - val_loss: 0.1117 - val_accuracy: 0.9709\n",
      "Epoch 23/23\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.1529 - accuracy: 0.9521 - val_loss: 0.1111 - val_accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, epochs = epochs, validation_data = (validation_X,validation_y), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb319701",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ccd71eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80565758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 97.34%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(validation_X, validation_y, verbose=0)\n",
    "print(\"{}: {:.2f}%\".format(\"accuracy\", scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3b7c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "3 => 3\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "3 => 3\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "3 => 4\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "0 => 0\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "2 => 2\n"
     ]
    }
   ],
   "source": [
    "# train_X[0:1].shape\n",
    "print(\"{} => {}\".format(np.argmax(train_y[0]),np.argmax(model.predict(train_X[0:1]))))\n",
    "print(\"{} => {}\".format(np.argmax(train_y[104]),np.argmax(model.predict(train_X[104:105]))))\n",
    "print(\"{} => {}\".format(np.argmax(train_y[440]),np.argmax(model.predict(train_X[400:401]))))\n",
    "print(\"{} => {}\".format(np.argmax(train_y[550]),np.argmax(model.predict(train_X[550:551]))))\n",
    "print(\"{} => {}\".format(np.argmax(train_y[1204]),np.argmax(model.predict(train_X[1204:1205]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0804852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
